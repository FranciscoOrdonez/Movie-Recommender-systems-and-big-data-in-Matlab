Minimize a continuous differentialble multivariate function. Starting point
  is given by "X" (D by 1), and the function named in the string "f", must
  return a function value and a vector of partial derivatives. The Polack-
  Ribiere flavour of conjugate gradients is used to compute search directions,
  and a line search using quadratic and cubic polynomial approximations and the
  Wolfe-Powell stopping criteria is used together with the slope ratio method
  for guessing initial step sizes. Additionally a bunch of checks are made to
  make sure that exploration is taking place and that extrapolation will not
  be unboundedly large. The "length" gives the length of the run: if it is
  positive, it gives the maximum number of line searches, if negative its
  absolute gives the maximum allowed number of function evaluations. You can
  (optionally) give "length" a second component, which will indicate the
  reduction in function value to be expected in the first line-search (defaults
  to 1.0). The function returns when either its length is up, or if no further
  progress can be made (ie, we are at a minimum, or so close that due to
  numerical problems, we cannot get any closer). If the function terminates
  within a few iterations, it could be an indication that the function value
  and derivatives are not consistent (ie, there may be a bug in the
  implementation of your "f" function). The function returns the found
  solution "X", a vector of function values "fX" indicating the progress made
  and "i" the number of iterations (line searches or function evaluations,
  depending on the sign of "length") used.
 
  Usage: [X, fX, i] = fmincg(f, X, options, P1, P2, P3, P4, P5)
